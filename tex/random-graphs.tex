%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Random Graphs}
\label{chap:random_graphs}


See Bollob{\'a}s~\cite{Bollobas2001}.

Random graphs are both highly predictable and easily built, and these are the reasons why they are so interesting. The most common way to generate them is given by Erdos-Renyi.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Erd\H{o}s-R{\'e}nyi graphs}


\begin{definition}[Random Graph] A random graph $G_{n,p}$ can be built by taking a vertex set of cardinality $n$ and, for each pair of vertices, draw an edge between them with probability $p$.

Formally, $G_{n,p}$ is the random variable equal to $G$ with probability $p^{|E(G)|}(1-p)^{|E(\bar{G})|}$, for each graph $G$ on $n$ vertices.
\end{definition}

One of the first properties of random graphs which makes them so pleasant to work with is the following

\begin{theorem}
  Let $H$ be any graph, and $0<p<1$. Then
$$\lim_{n\rightarrow +\infty}P\left[H\text{ is an induced subgraph of }G_{n,p}\right]=1$$
\end{theorem}
\begin{proof}[Sketch]
Instinctively, we would like to find a copy of $H$ in $G_{n,p}$ by iteratively finding an acceptable representant $h(v_i)$ in $G_{n,p}$ of every vertex $v_i$ of $V(H) = \{v_1, \dots, v_k\}$. How could such a strategy work ?
\begin{itemize}
\item Pick for $v_1$ any vertex $h(v_1)\in G_{n,p}$
\item Pick for $v_2$ any vertex $h(v_2)\in G_{n,p}$ such that $h(v_1)h(v_2)\in E(G_{n,p})$ if $v_1v_2\in E(H)$, and such that $h(v_1)h(v_2)\not \in E(G_{n,p})$ otherwise
\item \dots
\item Assuming you have found, for all $i\leq j\leq k$, a representant $h(v_i)$ for each vertex $v_i$, and such that $H[\{v_1,\dots,v_{j-1}\}]$ is isomorphic to $G_{n,p}[\{h(v_1),\dots,h(v_{j-1})\}]$, try to find a new vertex $h(v_j)$ such that $\forall i<j,h(v_i)h(v_j)\in E(G_{n,p})$ if  and only if $v_iv_j\in E(H)$.

  When $n$ is growing large, such a vertex will exist with high probability.
\end{itemize}
\end{proof}

\begin{proof}
  Formally, let us write $H_i = H[\{v_1,\dots,v_{j-1}\}]$, and denote
  the probability that $H$ is an induced subgraph of $G_{n,p}$ by $P[H
    \mapsto_{ind} G_{n,p}]$. We can roughly bound the probability that $H_i$, but not $H_{i+1}$, is an induced subgraph of $G_{n,p}$ the following way :

  \begin{itemize}
  \item We put a copy of $H_i$ at any of the $\binom n i$ different $i$-subsets of $V(G_{n,p})$.

    This can be done, each time, in $i!$ different ways as the vertices $\{v_1, \dots, v_i\}$ can be permuted

  \item We compute the probability that no other vertex of $G_{n,p}$ can be used to complete our current copy of $H_i$ into a copy of $H_{i+1}$. The probability that such a vertex is acceptable being
    $$p^{d_{H_{i+1}}(v_{i+1})}(1-p)^{i-d_{H_{i+1}}(v_{i+1})}\geq min(p, 1-p)^i$$
    the property that none of the $n-i$ vertices left is acceptable is at most
    $$\left({ 1- min(p, 1-p)^i } \right)^{(n-i)}$$
  \end{itemize}

  As $0<p<1$, we can write $0<\epsilon = min(p, 1-p)$ and thus, the probability that $H_i$, but not $H_{i+1}$, is a induced subgraph of $G_{n,p}$ is at most $$i!\binom n i (1-\epsilon^i)^{n-i}\leq i! n^i (1-\epsilon^i)^{n-i} = o(1/n)$$
Which is asymptotically equal to 0 as $n$ grows.

Thus

\begin{align*}
  P[H \mapsto_{ind} G_{n,p}]&=1 - P[H_2 \mapsto_{ind} G_{n,p}, H_3\not \mapsto_{ind} G_{n,p}]\\
  &-P[H_3 \mapsto_{ind} G_{n,p}, H_4\not \mapsto_{ind} G_{n,p}]\\
  &\dots\\
  &-P[H_{k-1} \mapsto_{ind} G_{n,p}, H_k\not \mapsto_{ind} G_{n,p}]\\
  P[H \mapsto_{ind} G_{n,p}]&\geq 1-\sum_{i\leq k}i!n^i(1-\epsilon^i)^{n-i}\\
  &\geq 1-k\times o(1/n)\\
\end{align*}

Which proves the result.

\end{proof}

This proof also gives us a simple algorithm to find a copy of a graph $H$ into a random graph $G_{n,p}$. While obviously such an algorithm will not always find the copy of $H$ if it exists, the probability of a successful run will tend toward $1$ as proved immediately above.

\begin{lstlisting}
def find_induced(H, G):

    # f is the function from V(H) to V(G) we
    # are attempting to define
    f = {}

    # leftovers is the set of vertices of G which have not yet
    # been used by f
    G_leftovers = G.vertices()

    # Set of vertices for which no representant has been found yet
    H_leftovers = H.vertices()

    # While the function is not complete
    while H_leftovers:

        # We look for the next vertex of H
        v = H_leftovers.pop(0)

        # ... and look for its possible image
        candidates = [u for u in G_leftovers if
          all([ H.has_edge(h,v) == G.has_edge(f_h,u)
            for h,f_h in f.iteritems()])]

        if not candidates:
            raise ValueError("No copy of H has been found in G")

        # We pick the first of them
        f[v] = candidates[0]
        G_leftovers.remove(f[v])

    return f
\end{lstlisting}

Describe the random graph model of Erd\H{o}s and
R{\'e}nyi~\cite{ErdosRenyi1959}. Algorithms for efficient generation
of random networks; see Batagelj and
Brandes~\cite{BatageljBrandes2005}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Small-world networks}

The small-world network model of Watts and
Strogatz~\cite{WattsStrogatz1998}. The economic small-world model of
Latora and Marchiori~\cite{LatoraMarchiori2003}. See also
Milgram~\cite{Milgram1967}, Newman~\cite{Newman2003}, and Albert and
Barab{\'a}si~\cite{AlbertBarabasi2002}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Scale-free networks}

The power-law degree distribution model of Barab{\'a}si and
Albert~\cite{BarabasiAlbert1999}. See also Newman~\cite{Newman2003},
and Albert and Barab{\'a}si~\cite{AlbertBarabasi2002}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Evolving networks}

Preferential attachment models. See Newman~\cite{Newman2003},
and Albert and Barab{\'a}si~\cite{AlbertBarabasi2002}.
