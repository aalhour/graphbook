%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% This file is part of the book
%%
%% Algorithmic Graph Theory
%% http://code.google.com/p/graph-theory-algorithms-book/
%%
%% Copyright (C) 2009, 2010, 2011 Minh Van Nguyen <nguyenminh2@gmail.com>
%% Copyright (C) 2010 Nathann Cohen <nathann.cohen@gmail.com>
%%
%% See the file COPYING for copying conditions.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Random Graphs}
\label{chap:random_graphs}

A random\index{random graph} graph can be thought of as being a member
from a collection of graphs having some common properties. Recall that
Algorithm~\ref{alg:trees_forests:random_binary_tree} allows us to
generate a random binary tree having at least one vertex. Fix a
positive integer $n$ and let $\cT$ be a collection of all binary trees
on $n$ vertices. It can be infeasible to generate all members of
$\cT$, so for most purposes we are only interested in randomly
generating a member of $\cT$. A binary tree of order $n$ generated in
this manner is said to be a random\index{random graph} graph. For
example, Algorithm~\ref{alg:random_graphs:random_simple_graph}
presents a procedure to construct a random graph that is simple and
undirected; the procedure is adapted from pages~4--7 of
Lau~\cite{Lau2007}.

\begin{itemize}
\item See Bollob{\'a}s~\cite{Bollobas2001}.

\item See Gerke~et~al.~\cite{GerkeEtAl2008} for a random planar graph
  process.

\item See Fusy~\cite{Fusy2009} for a linear algorithm on uniform
  random sampling of planar graphs.

\item See Broutin~\cite{Broutin2007} on random trees.
\end{itemize}

\begin{algorithm}[!htbp]
\index{algorithm!random}
\index{simple graph!random}
\input{algorithm/random-graphs/random-simple-graph.tex}
\caption{Random simple undirected graph.}
\label{alg:random_graphs:random_simple_graph}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Binomial and Erd\H{o}s-R{\'e}nyi models}

This section considers two closely related common models of random
graphs: the binomial model and the Erd\H{o}s-R\'enyi model. Fix a
positive integer $n$, a probability $p$, and a vertex set
$V = \{1, 2, \dots, n\}$. The
\emph{binomial}\index{random graph!binomial}~(or
\emph{Bernoulli})\index{random graph!Bernoulli} random graph model,
denoted $G(n,p)$, is formally a probability\index{probability space}
space over the set of undirected graphs on $n$ vertices. If $G$ is any
element of the probability space $G(n,p)$ and $ij$ is any edge, then
$ij$ occurs as an edge of $G$ independently with probability $p$. In
symbols, for any $i,j \in V$ we have
\[
\Pr[ij \in E(G)]
=
p
\]
where all such events are mutually independent. Equivalently the model
$G(n,p)$ considers the collection of all undirected graphs on $n$
vertices, each such graph having at most $\binom{n}{2}$ edges, $m$
actual edges, and an associated probability
%%
\begin{equation}
\label{eqn:random_graphs:probability_distribution_binomial_random_graph}
p^m (1 - p)^{\binom{n}{2} - m}.
\end{equation}
%%
Notice the latter's resemblance to the
binomial\index{binomial distribution} distribution. By
$G \in G(n,p)$ we mean that $G$ is a random graph of the space
$G(n,p)$ and having probability
distribution~\eqref{eqn:random_graphs:probability_distribution_binomial_random_graph}.

To generate a random graph in $G(n,p)$, start with $G$ being the
null\index{null graph} graph. Consider each of the $\binom{n}{2}$
possible edges in some order and add it independently to $G$ with
probability $p$. Repeat the process until $G$ contains the desired
number of edges. The expected number of edges in the resulting graph
is
\[
p \cdot \binom{n}{2}
=
\frac{p \cdot n!} {2! (n - 2)!}
\]
and the expected total degree is
\[
2p \cdot \binom{n}{2}
=
pn(n - 1).
\]
Then the expected degree of each edge is $p(n - 1)$.

Let $N$ be a fixed nonnegative integer. Like the model $G_{n,p}$, in
the model $G_{n,N}$ we consider all undirected graphs on $n$
vertices. However, each such graph in $G_{n,N}$ has exactly $N$ edges,
hence $G_{n,N}$ is a collection of $\binom{\binom{n}{2}} {N}$ graphs
on exactly $N$ edges, each of which is selected with equal
probability. To generate a graph in $G_{n,N}$, choose $N$ of the
possible $\binom{n}{2}$ edges independently and uniformly at random.

One of the first properties of random graphs which makes them so pleasant to work with is the following

\begin{theorem}
  Let $H$ be any graph, and $0<p<1$. Then
$$\lim_{n\to +\infty}P\left[H\text{ is an induced subgraph of }G_{n,p}\right]=1$$
\end{theorem}
\begin{proof}[Sketch]
Instinctively, we would like to find a copy of $H$ in $G_{n,p}$ by iteratively finding an acceptable representant $h(v_i)$ in $G_{n,p}$ of every vertex $v_i$ of $V(H) = \{v_1, \dots, v_k\}$. How could such a strategy work ?
\begin{itemize}
\item Pick for $v_1$ any vertex $h(v_1)\in G_{n,p}$
\item Pick for $v_2$ any vertex $h(v_2)\in G_{n,p}$ such that $h(v_1)h(v_2)\in E(G_{n,p})$ if $v_1v_2\in E(H)$, and such that $h(v_1)h(v_2)\not \in E(G_{n,p})$ otherwise
\item \dots
\item Assuming you have found, for all $i\leq j\leq k$, a representant $h(v_i)$ for each vertex $v_i$, and such that $H[\{v_1,\dots,v_{j-1}\}]$ is isomorphic to $G_{n,p}[\{h(v_1),\dots,h(v_{j-1})\}]$, try to find a new vertex $h(v_j)$ such that $\forall i<j,h(v_i)h(v_j)\in E(G_{n,p})$ if  and only if $v_iv_j\in E(H)$.

  When $n$ is growing large, such a vertex will exist with high probability.
\end{itemize}
\end{proof}

\begin{proof}
  Formally, let us write $H_i = H[\{v_1,\dots,v_{j-1}\}]$, and denote
  the probability that $H$ is an induced subgraph of $G_{n,p}$ by $P[H
    \mapsto_{ind} G_{n,p}]$. We can roughly bound the probability that $H_i$, but not $H_{i+1}$, is an induced subgraph of $G_{n,p}$ the following way :

  \begin{itemize}
  \item We put a copy of $H_i$ at any of the $\binom n i$ different $i$-subsets of $V(G_{n,p})$.

    This can be done, each time, in $i!$ different ways as the vertices $\{v_1, \dots, v_i\}$ can be permuted

  \item We compute the probability that no other vertex of $G_{n,p}$ can be used to complete our current copy of $H_i$ into a copy of $H_{i+1}$. The probability that such a vertex is acceptable being
    $$p^{d_{H_{i+1}}(v_{i+1})}(1-p)^{i-d_{H_{i+1}}(v_{i+1})}\geq min(p, 1-p)^i$$
    the property that none of the $n-i$ vertices left is acceptable is at most
    $$\left({ 1- min(p, 1-p)^i } \right)^{(n-i)}$$
  \end{itemize}

  As $0<p<1$, we can write $0<\epsilon = min(p, 1-p)$ and thus, the probability that $H_i$, but not $H_{i+1}$, is a induced subgraph of $G_{n,p}$ is at most $$i!\binom n i (1-\epsilon^i)^{n-i}\leq i! n^i (1-\epsilon^i)^{n-i} = o(1/n)$$
Which is asymptotically equal to 0 as $n$ grows.

Thus

\begin{align*}
  P[H \mapsto_{ind} G_{n,p}]&=1 - P[H_2 \mapsto_{ind} G_{n,p}, H_3\not \mapsto_{ind} G_{n,p}]\\
  &-P[H_3 \mapsto_{ind} G_{n,p}, H_4\not \mapsto_{ind} G_{n,p}]\\
  &\dots\\
  &-P[H_{k-1} \mapsto_{ind} G_{n,p}, H_k\not \mapsto_{ind} G_{n,p}]\\
  P[H \mapsto_{ind} G_{n,p}]&\geq 1-\sum_{i\leq k}i!n^i(1-\epsilon^i)^{n-i}\\
  &\geq 1-k\times o(1/n)\\
\end{align*}

Which proves the result.

\end{proof}

This proof also gives us a simple algorithm to find a copy of a graph $H$ into a random graph $G_{n,p}$. While obviously such an algorithm will not always find the copy of $H$ if it exists, the probability of a successful run will tend toward $1$ as proved immediately above.

\begin{lstlisting}
def find_induced(H, G):

    # f is the function from V(H) to V(G) we
    # are attempting to define
    f = {}

    # leftovers is the set of vertices of G which have not yet
    # been used by f
    G_leftovers = G.vertices()

    # Set of vertices for which no representant has been found yet
    H_leftovers = H.vertices()

    # While the function is not complete
    while H_leftovers:

        # We look for the next vertex of H
        v = H_leftovers.pop(0)

        # ... and look for its possible image
        candidates = [u for u in G_leftovers if
          all([ H.has_edge(h,v) == G.has_edge(f_h,u)
            for h,f_h in f.iteritems()])]

        if not candidates:
            raise ValueError("No copy of H has been found in G")

        # We pick the first of them
        f[v] = candidates[0]
        G_leftovers.remove(f[v])

    return f
\end{lstlisting}

Describe the random graph model of Erd\H{o}s and
R{\'e}nyi~\cite{ErdosRenyi1959}. Algorithms for efficient generation
of random networks; see Batagelj and
Brandes~\cite{BatageljBrandes2005}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Small-world networks}

The small-world network model of Watts and
Strogatz~\cite{WattsStrogatz1998}. The economic small-world model of
Latora and Marchiori~\cite{LatoraMarchiori2003}. See also
Milgram~\cite{Milgram1967}, Newman~\cite{Newman2003}, and Albert and
Barab{\'a}si~\cite{AlbertBarabasi2002}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Scale-free networks}

The power-law degree distribution model of Barab{\'a}si and
Albert~\cite{BarabasiAlbert1999}. See also Newman~\cite{Newman2003},
and Albert and Barab{\'a}si~\cite{AlbertBarabasi2002}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Evolving networks}

Preferential attachment models. See Newman~\cite{Newman2003},
and Albert and Barab{\'a}si~\cite{AlbertBarabasi2002}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Problems}

\begin{problem}
\item Modify Algorithm~\ref{alg:random_graphs:random_simple_graph} to
  generate the following random graphs.
  %%
  \begin{enumerate}[(a)]
  \item Simple weighted, undirected graph.

  \item Simple digraph.

  \item Simple weighted digraph.
  \end{enumerate}
\end{problem}
