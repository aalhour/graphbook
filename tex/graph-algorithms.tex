%%-----------------------------------------------------------------------%%
%%--- Graph Algorithms --------------------------------------------------%%

\chapter{Graph Algorithms}
\label{chap:graph_algorithms}

Graph algorithms have many applications. Suppose you are a salesman
with a product you would like to sell in several cities. To determine
the cheapest travel route from city-to-city, you must effectively
search a graph having weighted edges for the ``cheapest'' route
visiting each city once. Each vertex denotes a city you must visit and
each edge has a weight indicating either the distance from one city to
another or the cost to travel from one city to another.

Shortest path algorithms are some of the most important algorithms in
algorithmic graph theory. We shall examine several in this chapter.


%%-----------------------------------------------------------------------%%
%%--- Graph searching ---------------------------------------------------%%

\section{Graph searching}

This section discusses algorithms for

\begin{itemize}
\item
breadth-first searches,

\item
depth-first searches, and

\item
we explain how these relate to determining a graph's connectivity.
\end{itemize}


%%--- Breadth-first search ----------------------------------------------%%

\subsection{Breadth-first search}

\emph{Breadth-first search} (BFS) is a strategy for running through
the nodes of a graph. Suppose you want to count the number of vertices
(or edges) satisfying a property
$P$. Algorithm~\ref{alg:graph_algorithms:breadth_first_search}
presents a technique for finding the number of vertices satisfying $P$.
\index{BFS}
\index{breadth-first search} 

\begin{algorithm}[!htpb]
\SetLine
\dontprintsemicolon  % no semicolon at end of pseudocode statements
%% data section
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\SetKwData{Count}{count}
\SetKwData{False}{False}
\SetKwData{True}{True}
%% input/output
\Input{A connected graph $G = (V, E)$ (and, optionally, a starting or
  ``root'' vertex $v_0 \in V$). A property $P$ to be tested.}
\Output{The number of vertices of $G$ satisfying $P$.}
\BlankLine
%% algorithm body
Create a queue $Q$ of ``unseen'' vertices initially containing a
starting vertex $v_0$.\;

Start a list $T$ of ``already seen'' vertices initially empty.\;

$\Count \leftarrow 0$\;

\For{$w \in Q$}{
  Test $w$ for $P$.\;
  \If{$P(w) = \True$}{
    $\Count \leftarrow \Count + 1$\label{abc:step:counter}
  }
  Add all neighbors of $w$ not in $T$ to $Q$.\;
  Remove all ``seen'' vertices $w$ from $Q$.\;
  Add such $w$ to $T$.\;
  \If{$T = V$}{
    \Return \Count
  }
}
\caption{Breadth-first search.}
\label{alg:graph_algorithms:breadth_first_search}
\end{algorithm}

%Algorithm to find a vertex satisfying property P.
%INPUT: Connected graph $G=(V,E)$ and a fixed
%starting vertex $v\in V$.
%OUTPUT:
%True if a vertex is found satisfying P,
%False otherwise.
%1. Start a queue Q containing $v$. Start a
%list of tested vertices, T, initially empty.
%2. For each element w of the queue:
%(a) Test w for P (stop if True).
%(b) Add all neighbors of w not yet tested
%to the queue.
%(c) Remove all tested vertices from the queue
%and add them to T.
%(d) If T=V, stop and return False.

Another version of
Algorithm~\ref{alg:graph_algorithms:breadth_first_search} is where you
are searching the graph for a vertex (or edge) satisfying a certain
property $P$. In that situation, you simply quit at the step where you
increment the counter, i.e. line~7 in
Algorithm~\ref{alg:graph_algorithms:breadth_first_search}. Other
variations are also possible as well.

For the example of the graph in
Figure~\ref{fig:introduction:types_of_walks}, the list of distances
from vertex \verb!a! to any other vertex is
%
\begin{center}
\fontsize{9pt}{9pt}
\selectfont
\tt
\begin{lstlisting}
[['a', 0], ['b', 1], ['c', 2], ['d', 3], ['e', 1], ['f', 2], ['g', 2]]
\end{lstlisting}
\end{center}
%
To create this list,
%
\begin{itemize}
\item
Start at \verb!a! and compute the distance from \verb!a! to itself.

\item
Move to each neighbor of \verb!a!, namely \verb!b! and \verb!e!, and
compute the distance from \verb!a! to each of them.

\item
Move to each ``unseen'' neighbor of \verb!b!, namely just \verb!c!,
and compute the distance from \verb!a! to it.

\item
Move to each ``unseen'' neighbor of \verb!e!, namely just \verb!f!,
and compute the distance from \verb!a! to it.

\item
Move to each ``unseen'' neighbor of \verb!c!, namely just \verb!d!,
and compute the distance from \verb!a! to it.

\item
Move to each ``unseen'' neighbor of \verb!f!, namely just \verb!g!,
and compute the distance from \verb!a! to it.
\end{itemize}

As an example, here is some Sage code which implements BFS to compute
the list distances from a given vertex.
%
\begin{center}
\fontsize{9pt}{9pt}
\selectfont
\tt
\begin{lstlisting}
def graph_distance(G, v0):
    """
    Breadth first search algorithm to find the
    distance from a fixed vertex $v_0$ to any
    other vertex.

    INPUT:
        G - a connected graph
        v0 - a vertex

    OUTPUT:
        D - a list of distances to
            every other vertex

    EXAMPLES:
        sage: G = Graph({1: [2, 4], 2: [1, 4], 3: [2, 6],
                         4: [1, 3], 5: [4, 2], 6: [3, 1]})
        sage: v0 = 1
        sage: graph_distance(G,v0)
        [[1, 0], [2, 1], [3, 2], [4, 1], [5, 2], [6, 1]]
        sage: G = Graph({"a": ["b", "e"], "b": ["c", "e"], \
         "c": ["d", "e"], "d": ["f"], "e": ["f"], "f": ["g"], "g":["b"]})
        sage: v0 = "a"
        sage: graph_distance(G, v0)
        [['a', 0], ['b', 1], ['c', 2], ['d', 3], ['e', 1],
         ['f', 2], ['g', 2]]
        sage: G = Graph({1: [2,3], 2: [1, 3], 3: [2], 4: [5], 5: [6], 6: [5]})
        sage: v0 = 1
        sage: graph_distance(G, v0) # note G is disconnected
        [[1, 0], [2, 1], [3, 1]]
    """
    V = G.vertices()
    Q = [v0]
    T = []
    D = []
    while Q<>[] and T<>V:
        for v in Q:
            if not(v in T):
                D.append([v,G.distance(v0,v)])
            if v in Q:
                Q.remove(v)
            T.append(v)
            T = list(Set(T))
            Q = Q+[x for x in G.neighbors(v) if not(x in T+Q)]
            if T == V:
                break
    D.sort()
    print Q, T
    return D
\end{lstlisting}
\end{center}
%
\begin{exercise}
Using Sage's \verb!shortest_path! method, can you modify the above
function to return a list of shortest paths from $v_0$ to any other
vertex?
\end{exercise}


%%--- Depth-first search ------------------------------------------------%%

\subsection{Depth-first search}

A depth-first search is a type of algorithm that visits each vertex of
a graph, proceeding from vertex-to-vertex in this search but moving
along a spanning tree of that graph.

Suppose you have a normal $8 \times 8$ chess board in front of you,
with a single knight piece on the board. If you can find a sequence of
knight moves which visits each and every square exactly once, then you
will have found a so-called \emph{complete knight tour}.
\index{knight tour}
Naively, how do you find a complete knight tour? Intuitively, you
would make one knight move after another, recording each move to
ensure that you did not step on a square you have already visited,
until you could not make any more moves. It is very, very unlikely
that if do this you will have visited every square exactly once (if
you don't believe me, please try it yourself!). Acknowledging defeat,
at this stage, it might make sense to \emph{backtrack} a few moves and
try again, hoping you will not get ``stuck'' so soon. If you fail
again, try backtracking a few move moves and traverse yet another
path, hoping to make further progress. Repeat this until a compete
tour is found. This is an example of \emph{depth-first search}, also
sometimes called \emph{backtracking}.
\index{backtracking}

Similar to BFS, \emph{depth-first search} (DFS) is an algorithm for
traversing a graph. One starts at a \emph{root vertex} and explores as
\emph{far as possible} along each branch before, if necessary,
backtracking along a new path. It is easier to see what this means in
the case of a rooted tree than for more general graphs, as illustrated
below.
\index{depth-first search}
\index{DFS}

Suppose you want to count the number of vertices (or edges) satisfying
a property $P$.

\begin{algorithm}[!htpb]
\SetLine
\dontprintsemicolon  % no semicolon at end of pseudocode statements
%% data section
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\SetKwData{Count}{count}
\SetKwData{False}{False}
\SetKwData{True}{True}
%% input/output
\Input{A rooted tree $G = (V, E)$ with  root vertex $v_0 \in V$.}
\Output{\True if $G$ has a vertex satisfying $P$; \False otherwise.}
\BlankLine
%% algorithm body
Create a queue $Q$ of ``child'' vertices of the root $v_0$.\;
Initialize a list $S$ of ``seen'' vertices.\;
$\Count \leftarrow 0$\;
\For{$w \in Q$}{
  Test $w$ for $P$.\;
  \If{$P(w) = \True$}{
    $\Count \leftarrow \Count + 1$
  }
  Add $w$ to $S$.\;
  \If{$S = V$} {
    \Return \Count
  }
}
Call the DFS algorithm iteratively with the rooted subtree having $w$
and all its children as vertices and $w$ as the rooted vertex.
\caption{Depth-first search.}
\label{alg:graph_algorithms:depth_first_search}
\end{algorithm}

In the case of a graph, you can modify
Algorithm~\ref{alg:graph_algorithms:depth_first_search} to a so-called
iterative DFS. This modification applies DFS repeatedly with an
increasing depth of search at each step, until the diameter of the
graph is reached and all vertices are seen.

\subsection{Application: connectivity of a graph}

% This subsection is on how the above algorithms can be used
% to determine a graph's connectivity.

A simple algorithm to determine if a graph is connected 
might be described as follows:
\begin{itemize}

\item
Begin at any arbitrary vertex of the graph, $\Gamma=(V,E)$.

\item
Proceed from that vertex using either DFS or BFS, counting all
vertices reached.

\item
Once the connected component of the graph has been entirely traversed, 
if the number of vertices counted is equal to $|V|$, 
the graph is connected and otherwise it is disconnected.
\end{itemize}


%%-----------------------------------------------------------------------%%
%%--- Dijkstra's algorithm ----------------------------------------------%%

\section{Shortest path algorithms}

There are a number of different algorithms for computing a shortest
path in a weighted graph. Some only work if the graph has
no negative weight cycles. Some assume that there is a single 
start or source vertex. Some compute the shortest paths from
any vertex to any other, and also detect if the graph has
a negative weight cycle.

No matter what algorithm you use, the length of the shortest path 
cannot exceed the number of vertices in the graph.

\begin{lemma}
{\rm
Fix a vertex $v$ in the connected graph $G=(V,E)$ and let $n$ denote the
number of vertices of $G$, $n=|V|$.
If there are no negative weight cycles in $G$ then there 
exists a shortest path from $v$ 
to any other vertex $w\in V$ which uses at most $n-1$ edges.
}
\end{lemma}

{\bf proof:}
Suppose that $G$ contains no negative weight cycles. 
Observe that at most $n-1$ edges are required to construct a 
path from $v$ to any vertex $w$. Let $P$ denote such a path,

\[
P = (v_0=v\to v_1 \to v_2 \to \dots \to v_k = w). 
\]
Since $G$ has no negative weight cycles, the weight of $P$ is no less 
than the weight of $P'$, where
$P'$ is the same as $p$ except that all cycles have been removed. 
Thus, we can remove all cycles from $P$ and obtain a path $P'$ 
from $v$ to $w$ of lower weight. Since the
final path is acyclic, it must have no more than $n-1$ edges.
\qed

\subsection{Dijkstra's algorithm}

See Dijkstra~\cite{Dijkstra1959}, section~24.3 of
Cormen~et~al.~\cite{CormenEtAl2001}, and section~12.6 of Berman and
Paul~\cite{BermanPaul1997}.

Dijkstra's algorithm, discovered by E.~Dijkstra in 1959, is a graph
search algorithm that solves the single-source shortest path problem
for a graph with non-negative edge weights. For example, if the
vertices of a weighted graph represent cities and edge weights
represent distances between pairs of cities connected by a direct
road, Dijkstra's algorithm can be used to find the shortest route from
a fixed city to all other cities.

%It is remarkable that, at the present state of knowledge, given two
%distinct vertices $v, w$ of a graph $G=(V,E)$, the fastest algorithm
%determining a shortest path from $v$ to $w$ appears to be no faster (in general)
%than the fastest algorithm determining a shortest path from $v$ to
%\emph{any} other vertex of $G$.

Let $G = (V,E)$ be a graph with non-negative edge weights, $w(e)$ for
$e \in E$. Fix a start or source vertex $v_0 \in V$. The
\emph{length of a path} $P$ from $v \in V$ to $w \in V$ is the sum of
the edge weights for each edge in the path $P$, denoted
$\delta(P)$. We write $\delta(v,w)$ for the smallest value of
$\delta(P)$ for all paths $P$ from $v$ to $w$.
\index{path length}

Dijkstra's algorithm performs a number of steps, basically one step
for each vertex in $V$. We partition the vertex set $V$ into two
subsets: the set $F$ of vertices where we have found the shortest path
to $v_0$; and the ``queue'' $Q$ where we do not yet know for sure the
shortest path to $v_0$. The vertices $v \in F$ are labeled with
$\delta(v, v_0)$. The vertices $v \in Q$ are labeled with a temporary
label $L(v)$. This temporary label can be either $\infty$ if no path
from $v$ to $v_0$ has yet been examined, or an upper bound on
$\delta(v, v_0)$ obtained by computing $\delta(P)$ for a path $P$ from
$v$ to $v_0$ which has been found (but may not be the shortest path).

\begin{algorithm}[!htpb]
\SetLine
\dontprintsemicolon  % no semicolon at end of pseudocode statements
%% data section
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\SetKwData{Count}{count}
\SetKwData{False}{False}
\SetKwData{True}{True}
%% input/output
\Input{A connected graph $G = (V, E)$ having non-negative edge weights
and a starting vertex $v_0 \in V$. }
\Output{A shortest path from $v_0$ to an vertex in $V$.}
\BlankLine
%% algorithm body
Create a queue $Q$ of ``unseen'' vertices initially being
all of $V$.\;

Start a list $F$ of ``already seen'' vertices initially empty.\;

Initialize labels $L(v_0) = 0$ and $L(v) = \infty$ for all
$v \in V$ with $v \neq v_0$.\;

Find $v \in Q$ for which $L(v)$ is finite and minimum.\;

\eIf{\emph{no such $v$ exists}}{
  \Return
}{
  Label $v$ with the distance $\delta(v, v_0) = L(v)$.\;
  Add $v$ to $F$.\;
  Remove $v$ from $Q$.\;
  \If{$F = V$}{
    \Return
  }
}

\For{\emph{$w \in Q$ such that $w$ is adjacent to $v$}}{
  Replace $L(w)$ by $\min(L(w),\, L(v) + wt(v,w))$.\;
  Go to step 4.
}
\caption{Dijkstra's algorithm.}
\label{alg:graph_algorithms:dijkstra}
\end{algorithm}

The simplest implementation of Dijkstra's algorithm has
running time $O( | V |^2)=O(n^2)$ (where
$n=|V|$ is the number of vertices of the graph)\footnote{This 
can be improved, with some clever programming,
in the case of ``sparse'' graphs to $O(n\log n)$.}.

\begin{figure}[!htbp]
\centering
\begin{tikzpicture}
[nodedecorate/.style={shape=circle,inner sep=2pt,draw,thick},%
  arrowdecorate/.style={->,>=stealth,thick}]
% nodes or vertices
\node (0) at (0,0) [nodedecorate] {};
\node [below] at (0.south) {$0$};
\node (2) at (4,0) [nodedecorate] {};
\node [below] at (2.south) {$2$};
\node (4) at (8,0) [nodedecorate] {};
\node [below] at (4.south) {$4$};
\node (1) at (2,2.5) [nodedecorate] {};
\node [above] at (1.north) {$1$};
\node (3) at (6,2.5) [nodedecorate] {};
\node [above] at (3.north) {$3$};
% edges or lines
\path
(0) edge[arrowdecorate] node[left]{$10$} (1)
(0) edge[arrowdecorate] node[below]{$3$} (2)
(1) edge[arrowdecorate,bend left] node[right]{$1$} (2)
(1) edge[arrowdecorate] node[above]{$2$} (3)
(2) edge[arrowdecorate,bend left] node[left]{$4$} (1)
(2) edge[arrowdecorate] node[left]{$8$} (3)
(2) edge[arrowdecorate] node[below]{$2$} (4)
(3) edge[arrowdecorate,bend left] node[right]{$7$} (4)
(4) edge[arrowdecorate,bend left] node[left]{$9$} (3);
\end{tikzpicture}
\caption{Searching a weighted digraph using Dijkstra's algorithm.}
\label{fig:graph_algorithms:Dijkstra_algorithm_digraph}
\end{figure}
%sage: M = matrix([[0,10,3,0,0],[0,0,1,2,0],[0,4,0,8,2],[0,0,0,0,7],[0,0,0,9,0]])
%sage: D = DiGraph(M, format="weighted_adjacency_matrix")
%sage: D.plot(edge_labels=True, graph_border=True).show()

\begin{table}[!htbp]
\centering
\begin{tabular}{|ccccc|} \hline
$v_0$         & $v_1$         & $v_2$         & $v_3$         & $v_4$ \\\hline\hline
\underline{0} & $\infty$      & $\infty$      & $\infty$      & $\infty$ \\
              & 10            & \underline{3} & $\infty$      & $\infty$ \\
              & 7             &               & 11            & \underline{5} \\
              & \underline{7} &               & 11            & \\
              &               &               & \underline{9} & \\\hline
\end{tabular}
\caption{Stepping through Dijkstra's algorithm.}
\label{tab:graph_algorithms:working_through_Dijkstra_algorithm}
\end{table}

\begin{example}
Apply Dijkstra's algorithm to the graph in
Figure~\ref{fig:graph_algorithms:Dijkstra_algorithm_digraph}.
\end{example}

\begin{proof}[Solution]
Dijkstra's algorithm applied to the graph in
Figure~\ref{fig:graph_algorithms:Dijkstra_algorithm_digraph} yields
Table~\ref{tab:graph_algorithms:working_through_Dijkstra_algorithm}. The
steps below explain how this table is created.
%
\begin{enumerate}
\item
Start at $v_0$, let $Q = V$ and $F = \emptyset$. Initialize the labels
$L(v)$ to be $\infty$ for all $v \neq v_0$. This is the first row of
the table. Take the vertex $v_0$ out of the queue.

\item
Consider the set of all adjacent nodes to $v_0$. Replace the labels in
the first row by the weights of the associated edges. Underline the
smallest one and take its vertex (i.e. $v_2$) out of the queue. This
is the second row of the table.

\item
Consider the set of all nodes $w$ which are adjacent to $v_2$. Replace
the labels in the second row by $\min(L(w),\, L(v_2) + wt(v_2, w))$.
Underline the smallest one and take its vertex (i.e. $v_4$) out of the
queue. This is the third row of the table.

\item
Finally, start from $v_4$ and find the path to the remaining vertex
$v_3$ in $Q$. Take the smallest distance from $v_0$ to $v_3$. This is
the last row of the table.
\end{enumerate}
\end{proof}

\begin{exercise}
Dijkstra's algorithm applied to the graph in
Figure~\ref{fig:graph_algorithms:Dijkstra_directed_house_graph}
results in
Table~\ref{tab:graph_algorithms:another_walkthrough_Dijkstra}. Verify
the steps to create this table.
\end{exercise}

\begin{figure}[!htbp]
\centering
\begin{tikzpicture}
[nodedecorate/.style={shape=circle,inner sep=2pt,draw,thick},%
  arrowdecorate/.style={->,>=stealth,thick}]
% nodes or vertices
\node (0) at (4,0) [nodedecorate] {};
\node [below] at (0.south) {$0$};
\node (1) at (0,0) [nodedecorate] {};
\node [below] at (1.south) {$1$};
\node (2) at (0,3) [nodedecorate] {};
\node [above] at (2.north) {$2$};
\node (3) at (4,3) [nodedecorate] {};
\node [above] at (3.north) {$3$};
\node (4) at (7,1.5) [nodedecorate] {};
\node [right] at (4.east) {$4$};
% edges or lines
\path
(0) edge[arrowdecorate] node[below]{$1$} (1)
(0) edge[arrowdecorate,bend left=15] node[below right]{$3$} (2)
(0) edge[arrowdecorate] node[below]{$6$} (4)
(1) edge[arrowdecorate,bend left=20] node[left]{$1$} (2)
(1) edge[arrowdecorate] node[right]{$3$} (3)
(2) edge[arrowdecorate,bend left=15] node[above left]{$1$} (0)
(2) edge[arrowdecorate,bend left=20] node[right]{$2$} (1)
(2) edge[arrowdecorate] node[above]{$1$} (3)
(3) edge[arrowdecorate] node[right]{$3$} (0)
(3) edge[arrowdecorate,bend left=15] node[above]{$2$} (4)
(4) edge[arrowdecorate,bend left=15] node[below]{$1$} (3);
\end{tikzpicture}
\caption{Searching a directed house graph using Dijkstra's algorithm.}
\label{fig:graph_algorithms:Dijkstra_directed_house_graph}
\end{figure}
%sage: M = matrix([[0,1,3,0,6],[0,0,1,3,0],[1,2,0,1,0],[3,0,0,0,2],[0,0,0,1,0]])
%sage: D = DiGraph(M, format="weighted_adjacency_matrix")
%sage: D.plot(edge_labels=True, graph_border=True).show()

\begin{table}[!htbp]
\centering
\begin{tabular}{|ccccc|} \hline
$v_0$         & $v_1$         & $v_2$         & $v_3$         & $v_4$ \\\hline\hline
\underline{0} & $\infty$      & $\infty$      & $\infty$      & $\infty$ \\
              & \underline{1} & 3             & $\infty$      & 6 \\
              &               & \underline{2} & 4             & 6 \\
              &               &               & \underline{3} & 6 \\
              &               &               &               & \underline{5} \\\hline
\end{tabular}
\caption{Another walk-through of Dijkstra's algorithm.}
\label{tab:graph_algorithms:another_walkthrough_Dijkstra}
\end{table}


%%-----------------------------------------------------------------------%%
%%--- Bellman-Ford algorithm --------------------------------------------%%

\subsection{Bellman-Ford algorithm}

See section~24.1 of Cormen~et~al.~\cite{CormenEtAl2001}, and
section~8.5 of Berman and Paul~\cite{BermanPaul1997}.

The Bellman-Ford algorithm computes single-source shortest paths in a
weighted graph or digraph, where some of the edge weights may be
negative. Instead of the ``greedy'' approach that Dijkstra's algorithm
took, i.e. searching for the ``cheapest'' path, the Bellman-Ford
algorithm searches over all edges and keeps track of the shortest one
found as it searches.

The implementation below takes in a graph or digraph, and creates two
Python dictionaries \verb!dist! and \verb!predecessor!, keyed on the
list of vertices, which store the distance and shortest
paths. However, if a negative weight cycle exists~(in the case of a
digraph), then an error is raised.

\begin{center}
\fontsize{9pt}{9pt}
\selectfont
\tt
\begin{lstlisting}
def bellman_ford(Gamma, s):
    """
    Computes the shortest distance from s to all other vertices in Gamma.
    If Gamma has a negative weight cycle, then return an error.

    INPUT:

    - Gamma -- a graph.
    - s -- the source vertex.

    OUTPUT:

    - (d,p) -- pair of dictionaries keyed on the list of vertices,
      which store the distance and shortest paths.

    REFERENCE:

    http://en.wikipedia.org/wiki/Bellman-Ford_algorithm
    """
    P = []
    dist = {}
    predecessor = {}
    V = Gamma.vertices()
    E = Gamma.edges()
    for v in V:
        if v == s:
            dist[v] = 0
        else:
            dist[v] = infinity
        predecessor[v] = 0
    for i in range(1, len(V)):
        for e in E:
            u = e[0]
            v = e[1]
            wt = e[2]
            if dist[u] + wt < dist[v]:
                dist[v] = dist[u] + wt
                predecessor[v] = u
    # check for negative-weight cycles
    for e in E:
        u = e[0]
        v = e[1]
        wt = e[2]
        if dist[u] + wt < dist[v]:
            raise ValueError("Graph contains a negative-weight cycle")
    return dist, predecessor
\end{lstlisting}
\end{center}

Bellman-Ford runs in $O(|V|\cdot |E|)$-time, which is $O(n^3)$ for 
``dense'' connected graphs (where $n=|V|$).

Here are some examples.

\begin{center}
\fontsize{9pt}{9pt}
\selectfont
\tt
\begin{lstlisting}
sage: M = matrix([[0,1,4,0], [0,0,1,5], [0,0,0,3], [0,0,0,0]])
sage: G = Graph(M, format="weighted_adjacency_matrix")
sage: bellman_ford(G, G.vertices()[0])
  {0: 0, 1: 1, 2: 2, 3: 5}
\end{lstlisting}
\end{center}
%
The plot of this graph is given in
Figure~\ref{fig:graph_algorithms:Bellman_Ford_example}.

\begin{figure}[!htbp]
\centering
\begin{tikzpicture}
[nodedecorate/.style={shape=circle,inner sep=2pt,draw,thick},%
  linedecorate/.style={-,thick}]
% nodes or vertices
\node (0) at (0,0) [nodedecorate] {};
\node [below] at (0.south) {$0$};
\node (2) at (4,0) [nodedecorate] {};
\node [below] at (2.south) {$2$};
\node (1) at (1,2.5) [nodedecorate] {};
\node [above] at (1.north) {$1$};
\node (3) at (5,2.5) [nodedecorate] {};
\node [above] at (3.north) {$3$};
% edges or lines
\path
(0) edge[linedecorate] node[left]{$1$} (1)
(0) edge[linedecorate] node[below]{$4$} (2)
(1) edge[linedecorate] node[right]{$1$} (2)
(1) edge[linedecorate] node[above]{$5$} (3)
(2) edge[linedecorate] node[right]{$3$} (3);
\end{tikzpicture}
\caption{Shortest paths in a weighted graph using the Bellman-Ford
  algorithm.}
\label{fig:graph_algorithms:Bellman_Ford_example}
\end{figure}
%sage: M = matrix([[0,1,4,0],[0,0,1,5],[0,0,0,3],[0,0,0,0]])
%sage: G = Graph(M, format = "weighted_adjacency_matrix")
%sage: G.plot(graph_border=True, edge_labels=True).show()

The following example illustrates the case of a negative-weight cycle.

\begin{center}
\fontsize{9pt}{9pt}
\selectfont
\tt
\begin{lstlisting}
sage: M = matrix([[0,1,0,0],[1,0,-4,1],[1,1,0,0],[0,0,1,0]])
sage: G = DiGraph(M, format = "weighted_adjacency_matrix")
sage: bellman_ford(G, G.vertices()[0])
---------------------------------------------------------------------------
...
ValueError: Graph contains a negative-weight cycle
\end{lstlisting}
\end{center}
%
The plot of this graph is given in
Figure~\ref{fig:graph_algorithms:Bellman_Ford_negative_weights}.

\begin{figure}[!htbp]
\centering
\begin{tikzpicture}
[nodedecorate/.style={shape=circle,inner sep=2pt,draw,thick},%
  arrowdecorate/.style={->,>=stealth,thick}]
% nodes or vertices
\node (0) at (5,0) [nodedecorate] {};
\node [below] at (0.south) {$0$};
\node (1) at (1,0) [nodedecorate] {};
\node [below] at (1.south) {$1$};
\node (2) at (4,3) [nodedecorate] {};
\node [above] at (2.north) {$2$};
\node (3) at (0,3) [nodedecorate] {};
\node [above] at (3.north) {$3$};
% edges or lines
\path
(0) edge[arrowdecorate,bend left=15] node[below]{$1$} (1)
(1) edge[arrowdecorate,bend left=10] node[above]{$1$} (0)
(1) edge[arrowdecorate,bend left=15] node[left]{$-4$} (2)
(1) edge[arrowdecorate] node[left]{$1$} (3)
(2) edge[arrowdecorate] node[right]{$1$} (0)
(2) edge[arrowdecorate,bend left=15] node[right]{$1$} (1)
(3) edge[arrowdecorate] node[above]{$1$} (2);
\end{tikzpicture}
\caption{Searching a digraph with negative weight using the
  Bellman-Ford algorithm.}
\label{fig:graph_algorithms:Bellman_Ford_negative_weights}
\end{figure}
%sage: M = matrix([[0,1,0,0],[1,0,-4,1],[1,1,0,0],[0,0,1,0]])
%sage: G = Graph(M, format = "weighted_adjacency_matrix")
%sage: G.plot(graph_border=True, edge_labels=True).show()


%%-----------------------------------------------------------------------%%
%%--- Floyd-Warshall algorithm ------------------------------------------%%

\subsection{Floyd-Roy-Warshall algorithm}

See section~25.2 of Cormen~et~al.~\cite{CormenEtAl2001}, and section
14.4 of Berman and Paul~\cite{BermanPaul1997}.

The {\it Floyd-Roy-Warshall algorithm}, or the Floyd-Warshall algorithm,
is an algorithm for finding shortest paths in a weighted, directed 
graph. Like the Bellman-Ford algorithm, it allows for negative
edge weights and detects a negative weight cycle if one exists.
Assuming that there are no negative weight cycles, a single 
execution of the FRW algorithm will find the shortest 
paths between all pairs of vertices.

It was discovered independently by Bernard Roy in 1959, Robert 
Floyd in 1962 and by Stephen Warshall in 1962.

In some sense, the above algorithm is an example of 
``dynamic programming,'' which allows one to break the 
computation down to simpler steps using some sort of 
recursive procedure. 
The rough idea is as follows: Temporarily label the vertices of $G$
as $V=\{1,2,\dots,n\}$.
Call $SD(i,j,k)$ a shortest distance from vertex $i$ to 
vertex $j$ that only uses vertices $1$ through
$k$. This can be computed using the recursive
expression

\[
SD(i,j,k) = \min\{ SD(i,j,k-1), SD(i,k,k-1) + SD(k,j,k-1)\}.
\]
The key to the Floyd-Roy-Warshall algorithm 
lies in exploiting this formula.

If $n=|V|$ then this is a 
$O(n^3)$-time algorithm.
For comparison, the Bellman-Ford algorithm has complexity
$O(|V|\cdot |E|)$, which is $O(n^3)$-time for ``dense''
graphs. However, Bellman-Ford only yields the shortest
paths eminating from a {\it single} vertex.
To achieve comparable output, we would need to iterate
Bellman-Ford over {\it all} vertices, which would be an
 $O(n^4)$-time algorithm for ``dense'' graphs. Except
possibly for ``sparse'' graphs, Floyd-Roy-Warshall is better than
an interated implementation of Bellman-Ford.

Here is an implementation in Sage.
%
\begin{center}
\fontsize{9pt}{9pt}
\selectfont
\tt
\begin{lstlisting}

def floyd_roy_warshall(A):
    """
    Shortest paths

    INPUT: 
        A - weighted adjacency matrix 

    OUTPUT
        dist  - a matrix of distances of shortest paths
        paths - a matrix of shortest paths

    """
    G = Graph(A, format="weighted_adjacency_matrix")
    V = G.vertices()
    E = [(e[0],e[1]) for e in G.edges()]
    n = len(V)
    dist = [[0]*n for i in range(n)]
    paths = [[-1]*n for i in range(n)]
    # initialization step
    for i in range(n):
        for j in range(n):
            if (i,j) in E:
                paths[i][j] = j
            if i == j:
                dist[i][j] = 0
            elif A[i][j]<>0:
                dist[i][j] = A[i][j]
            else:
                dist[i][j] = infinity
    # iteratively finding the shortest path
    for j in range(n):
        for i in range(n):
            if i <> j:
                for k in range(n):
                    if k <> j:
                        if dist[i][k]>dist[i][j]+dist[j][k]:
                            paths[i][k] = V[j]
                        dist[i][k] = min(dist[i][k], dist[i][j] +dist[j][k])
    for i in range(n):
        if dist[i][i] < 0:
            raise ValueError, "A negative edge weight cycle exists."
    return dist, matrix(paths)   

\end{lstlisting}
\end{center}
%

Here are some examples.

%
%\begin{center}
%\fontsize{9pt}{9pt}
%\selectfont
%\tt
%\begin{lstlisting}
%
%        sage: A = matrix([[0,1,2,3],[0,0,2,1],[20,10,0,3],[11,12,13,0]]); A
%        sage: floyd_roy_warshall(A)
%        ([[0, 1, 2, 2], [12, 0, 2, 1], [14, 10, 0, 3], [11, 12, 13, 0]], 
%          [-1  1  2  1]
%          [ 3 -1  2  3]
%          [ 3 -1 -1  3]
%          [-1 -1 -1 -1])
%
%\end{lstlisting}
%\end{center}
%

%
%\begin{center}
%\fontsize{9pt}{9pt}
%\selectfont
%\tt
%\begin{lstlisting}
%
%        sage: A = matrix([[0,1,2,4],[0,0,2,1],[0,0,0,5],[0,0,0,0]])
%        sage: floyd_roy_warshall(A)
%        ([[0, 1, 2, 2], [+Infinity, 0, 2, 1], [+Infinity, +Infinity, 0, 5],
%          [+Infinity, +Infinity, +Infinity, 0]], 
%          [-1  1  2  1]
%          [-1 -1  2  3]
%          [-1 -1 -1  3]
%          [-1 -1 -1 -1])
%
%\end{lstlisting}
%\end{center}
%

%
\begin{center}
\fontsize{9pt}{9pt}
\selectfont
\tt
\begin{lstlisting}

        sage: A = matrix([[0,1,2,3],[0,0,2,1],[-5,0,0,3],[1,0,1,0]]); A
        sage: floyd_roy_warshall(A)
        Traceback (click to the left of this block for traceback)
        ...
        ValueError: A negative edge weight cycle exists.

\end{lstlisting}
\end{center}
%

The plot of this weighted digraph with four vertices appears in 
Figure \ref{fig:graph_algorithms:Floyd_Roy_Warshall_demo}.



\begin{figure}[!htbp]
\centering
\begin{tikzpicture}
[nodedecorate/.style={shape=circle,inner sep=2pt,draw,thick},%
  arrowdecorate/.style={->,>=stealth,thick}]
% nodes or vertices
\node (0) at (0,0) [nodedecorate] {};
\node [below] at (0.south) {$0$};
\node (1) at (6,0) [nodedecorate] {};
\node [below] at (1.south) {$1$};
\node (2) at (6,5) [nodedecorate] {};
\node [above] at (2.north) {$2$};
\node (3) at (0,5) [nodedecorate] {};
\node [above] at (3.north) {$3$};
% edges or lines
\path
(0) edge[arrowdecorate] node[below]{$1$} (1)
(0) edge[arrowdecorate,bend left=15] node[below left]{$2$} (2)
(0) edge[arrowdecorate,bend left=15] node[left]{$3$} (3)
(1) edge[arrowdecorate] node[right]{$2$} (2)
(1) edge[arrowdecorate] node[right]{$1$} (3)
(2) edge[arrowdecorate,bend left=15] node[above right]{$5$} (0)
(2) edge[arrowdecorate,bend left=10] node[below]{$3$} (3)
(3) edge[arrowdecorate,bend left=15] node[right]{$1$} (0)
(3) edge[arrowdecorate,bend left=10] node[above]{$1$} (2);
\end{tikzpicture}
\caption{Demonstrating the Floyd-Roy-Warshall algorithm.}
\label{fig:graph_algorithms:Floyd_Roy_Warshall_demo}
\end{figure}
%sage: A = matrix([[0,1,2,3],[0,0,2,1],[-5,0,0,3],[1,0,1,0]])
%sage: D = DiGraph(A, format="weighted_adjacency_matrix")
%sage: D.plot(edge_labels=True, graph_border=True).show()


%
\begin{center}
\fontsize{9pt}{9pt}
\selectfont
\tt
\begin{lstlisting}

        sage: A = matrix([[0,1,2,3],[0,0,2,1],[-1/2,0,0,3],[1,0,1,0]]); A
        sage: floyd_roy_warshall(A)
        ([[0, 1, 2, 2], [3/2, 0, 2, 1], [-1/2, 1/2, 0, 3/2], [1/2, 3/2, 1, 0]],
          [-1  1  2  1]
          [ 2 -1  2  3]
          [-1  0 -1  1]
          [ 2  2 -1 -1])

\end{lstlisting}
\end{center}
%

The plot of this weighted digraph with four vertices appears in 
Figure \ref{fig:FRW-algorithm-example1}.

% FIXME graphics

%% \begin{figure}[h!]
%% \begin{center}
%% \includegraphics[height=9cm,width=9cm]{FRW-algorithm-example1}
%% \end{center}
%% \caption{Another Floyd-Roy-Warshall algorithm example . }
%% \label{fig:FRW-algorithm-example1}
%% \end{figure}
%sage: A = matrix([[0,1,2,3],[0,0,2,1],[-1/2,0,0,3],[1,0,1,0]])
%sage: D = DiGraph(A, format="weighted_adjacency_matrix")
%sage: D.plot(edge_labels=True, graph_border=True).show()



%%-----------------------------------------------------------------------%%
%%--- Johnson's algorithm -----------------------------------------------%%

\subsection{Johnson's algorithm}

See section~25.3 of Cormen~et~al.~\cite{CormenEtAl2001} and
Johnson~\cite{Johnson1977}.

Let $G=(V,E)$ be a graph with edge weights but no negative cycles.


{\it Johnson's algorithm} finds a shortest path between all pairs of
vertices in a ``sparse'' directed graph. 
\index{Johnson's algorithm} 

%\begin{itemize}
%\item
%Add a new vertex $v_0$ with zero weight edges from it to all $v\in V$.
%
%\item
%Run the Bellman-Ford algorithm to check for negative weight cycles
%and find $h(v)$, 
%the least weight of a path from the new node $v_0$ to $v\in V$. 
%If this step detects a negative cycle, the algorithm is terminated.
%
%\item
%Reweight the edges using the vertices' $h(v)$ values: an edge from 
%$v\in V$ to $w\in V$, having length $wt(v,w)$, is given the new length 
%$wt(v,w) + h(v) - h(w)$.
%
%\item
%For each $v\in V$, run Dijkstra's algorithm and store the computed 
%least weight to other vertices. 
%\end{itemize}



\begin{algorithm}[!htpb]
\SetLine
\dontprintsemicolon  % no semicolon at end of pseudocode statements
%% data section
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\SetKwData{Count}{count}
\SetKwData{False}{False}
\SetKwData{True}{True}
%% input/output
\Input{A connected graph $G = (V, E)$ having (possibly negative) edge weights. }
\Output{A shortest path between all pairs of vertices in $V$
(or terminate if a negative edge cycle is detected).}
\BlankLine
%% algorithm body
Add a new vertex $v_0$ with zero weight edges from it to all $v\in V$.\;

Run the Bellman-Ford algorithm to check for negative weight cycles
and find $h(v)$, 
the least weight of a path from the new node $v_0$ to $v\in V$. 
If this step detects a negative cycle, the algorithm is terminated.\;

Reweight the edges using the vertices' $h(v)$ values: an edge from 
$v\in V$ to $w\in V$, having length $wt(v,w)$, is given the new length 
$wt(v,w) + h(v) - h(w)$.\;

For each $v\in V$, run Dijkstra's algorithm and store the computed 
least weight to other vertices. \;

\caption{Johnson's algorithm.}
\label{alg:graph_algorithms:johnson}
\end{algorithm}


The time complexity, for sparse graphs, is $O(|V|^2\log |V| + |V|\cdot
|E)|=O(n^2\log n)$ (where $n=|V|$ is the number of vertices of the
original graph$G$).
